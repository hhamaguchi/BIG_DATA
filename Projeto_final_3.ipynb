{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_final_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hhamaguchi/BIG_DATA/blob/master/Projeto_final_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "mrcygyxjakoq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip3 install -q numpy scipy pandas matplotlib twython\n",
        "!pip3 install -q numpy scipy pandas twython\n",
        "!pip3 install --upgrade -q gspread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WeMhTv06SuLi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "from twython import Twython\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a4CI7W5QlvQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Auth GDrive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebwA197tSSps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Credentials\n",
        "APP_KEY = 'B6cZTTHoeMr96AFfOsbVM2lGG'\n",
        "APP_SECRET = 'QhGt5p4TsGVK8tOds1fWc7hEDIFfrgnTW94fenpl1WneWLWqfz'\n",
        "OAUTH_TOKEN = '167813147-tP4vOpAZFlcfRLlqXWMfRqcBW3yvjNpzRAborOUu'\n",
        "OAUTH_TOKEN_SECRET = '8UshaZNMspgdN2kRuSlkPbBJfYdu3UDzOzZt0R1F8JoU7'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KXclSfDMSm9M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Conn on twitter\n",
        "twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
        "\n",
        "#twitter.verify_credentials()\n",
        "#twitter.get_home_timeline()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gpflI08QhlUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Query on twitter\n",
        "def queryTwitterToDF(q):\n",
        "  query = { 'q': q, 'count': 25, 'lang': 'pt', 'result_type': 'mixed'}\n",
        "  result = twitter.search(**query)\n",
        "  dict_ = {'user': [],'text': [], 'favorite_count': []}  \n",
        "  for status in result['statuses']:  \n",
        "      dict_['user'].append(status['user'])\n",
        "      dict_['text'].append(status['text'])\n",
        "      dict_['favorite_count'].append(status['favorite_count'])\n",
        "  df = pd.DataFrame(dict_)  \n",
        "  df.sort_values(by='favorite_count')\n",
        "  return df\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hgrz4FycBe6U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_direita = pd.concat([queryTwitterToDF('#alckmin'), queryTwitterToDF('#extremaesquerda'),\n",
        "                      queryTwitterToDF('#conservador'), queryTwitterToDF('#candidatodedireita'),\n",
        "                      queryTwitterToDF('#bolsomito'), queryTwitterToDF('#partidodedireita'),\n",
        "                      queryTwitterToDF('#PSDB'), queryTwitterToDF('#PFL'),\n",
        "                      queryTwitterToDF('#petralhas')], ignore_index=True)\n",
        "df_dir = df_direita.iloc[0:100,:]\n",
        "#print(df_dir.shape)\n",
        "#df_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qsJjYZpK95kE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_esquerda = pd.concat([queryTwitterToDF('#lula'), queryTwitterToDF('#extremadireita'),\n",
        "                      queryTwitterToDF('#lulalivre'), queryTwitterToDF('#candidatodeesquerda'),\n",
        "                      queryTwitterToDF('#haddad'), queryTwitterToDF('#partidodeesquerda'),\n",
        "                      queryTwitterToDF('#PT'), queryTwitterToDF('#golpe'),\n",
        "                      queryTwitterToDF('#coxinhas')], ignore_index=True)\n",
        "df_esq = df_esquerda.iloc[0:100,:]\n",
        "#print(df_esq.shape)\n",
        "#df_esq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UDYl-ZKhNJlJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_neutro = pd.concat([queryTwitterToDF('-#lula'), queryTwitterToDF('-#extremadireita'),\n",
        "                      queryTwitterToDF('-#lulalivre'), queryTwitterToDF('-#candidatodeesquerda'),\n",
        "                      queryTwitterToDF('-#haddad'), queryTwitterToDF('-#partidodeesquerda'),\n",
        "                      queryTwitterToDF('-#PT'), queryTwitterToDF('-#golpe'),\n",
        "                      queryTwitterToDF('-#coxinhas'), queryTwitterToDF('-#alckmin'), \n",
        "                      queryTwitterToDF('-#extremaesquerda'), queryTwitterToDF('-#conservador'), \n",
        "                      queryTwitterToDF('-#candidatodedireita'), queryTwitterToDF('-#bolsomito'), \n",
        "                      queryTwitterToDF('-#partidodedireita'), queryTwitterToDF('-#PSDB'), queryTwitterToDF('-#PFL'),\n",
        "                      queryTwitterToDF('-#petralhas')], ignore_index=True)\n",
        "\n",
        "df_n = df_neutro.iloc[0:100,:]\n",
        "#print(df_n.shape)\n",
        "#df_n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JfZUGUOngnV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_direita.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4qQK2W7gnv1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df_esquerda['user']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0aarYCKHn4AG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sh = gc.open('twitter_politico')\n",
        "direita_sheet = sh.get_worksheet(0)\n",
        "esquerda_sheet = sh.get_worksheet(1)\n",
        "neutro_sheet = sh.get_worksheet(2)\n",
        "\n",
        "for index, row in df_dir.iterrows():\n",
        "  direita_sheet.update_acell('A' + str(index + 1), row['text'])\n",
        "\n",
        "for index, row in df_esq.iterrows():\n",
        "  esquerda_sheet.update_acell('A' + str(index + 1), row['text'])\n",
        "\n",
        "for index, row in df_n.iterrows():\n",
        "  neutro_sheet.update_acell('A' + str(index + 1), row['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1pNxUPJ-HuvJ",
        "colab_type": "code",
        "outputId": "9500e2b2-a1a2-4d0f-99f7-ecb57ef398a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load data to DF.\n",
        "sh = gc.open('twitter_politico')\n",
        "direita_sheet = sh.get_worksheet(0)\n",
        "esquerda_sheet = sh.get_worksheet(1)\n",
        "neutro_sheet = sh.get_worksheet(2)\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "dict_ = {'text': [], 'label': []}\n",
        "for row in direita_sheet.get_all_values():\n",
        "  dict_['text'].append(row[0])\n",
        "  dict_['label'].append(0)\n",
        "\n",
        "for row in esquerda_sheet.get_all_values():\n",
        "  dict_['text'].append(row[0])\n",
        "  dict_['label'].append(1)\n",
        "\n",
        "for row in neutro_sheet.get_all_values():\n",
        "  dict_['text'].append(row[0])\n",
        "  dict_['label'].append(2)\n",
        "  \n",
        "df = pd.DataFrame(dict_)\n",
        "\n",
        "print(df.shape)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4nrgd4m-I5lS",
        "colab_type": "code",
        "outputId": "6517ec1a-9feb-4bf9-d5bd-f56ce7d1bd61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "cell_type": "code",
      "source": [
        "# Creating TDIDF Matrix\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "X_TF = count_vect.fit_transform(df['text'])\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X = tfidf_transformer.fit_transform(X_TF)\n",
        "print(type(X))\n",
        "print(X.shape)\n",
        "print(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "(300, 1368)\n",
            "  (0, 1298)\t0.2255589986677397\n",
            "  (0, 1134)\t0.08901836891018995\n",
            "  (0, 1074)\t0.26611714586639\n",
            "  (0, 987)\t0.23144984057019644\n",
            "  (0, 884)\t0.2549567663175079\n",
            "  (0, 852)\t0.24583807226706486\n",
            "  (0, 790)\t0.26611714586639\n",
            "  (0, 613)\t0.08099893558050877\n",
            "  (0, 599)\t0.17446177617623862\n",
            "  (0, 472)\t0.2549567663175079\n",
            "  (0, 447)\t0.26611714586639\n",
            "  (0, 414)\t0.26611714586639\n",
            "  (0, 413)\t0.2549567663175079\n",
            "  (0, 258)\t0.26611714586639\n",
            "  (0, 131)\t0.1856221557251208\n",
            "  (0, 90)\t0.26611714586639\n",
            "  (0, 79)\t0.2549567663175079\n",
            "  (0, 74)\t0.26611714586639\n",
            "  (1, 1352)\t0.37078673451230126\n",
            "  (1, 1258)\t0.37078673451230126\n",
            "  (1, 1225)\t0.27155795315834713\n",
            "  (1, 1167)\t0.27155795315834713\n",
            "  (1, 1163)\t0.31429346317368545\n",
            "  (1, 1082)\t0.16425071490893572\n",
            "  (1, 1013)\t0.2388424353380627\n",
            "  :\t:\n",
            "  (296, 235)\t0.3074119421780736\n",
            "  (296, 126)\t0.3074119421780736\n",
            "  (297, 1335)\t0.6056490429815283\n",
            "  (297, 869)\t0.40521611358889265\n",
            "  (297, 520)\t0.6432996144225656\n",
            "  (297, 333)\t0.23485047180546822\n",
            "  (298, 1134)\t0.11032533742207903\n",
            "  (298, 1081)\t0.2868484568949493\n",
            "  (298, 987)\t0.2868484568949493\n",
            "  (298, 975)\t0.3159818767337734\n",
            "  (298, 869)\t0.19191909611502087\n",
            "  (298, 864)\t0.20702013783988396\n",
            "  (298, 810)\t0.3159818767337734\n",
            "  (298, 503)\t0.3298135460236378\n",
            "  (298, 421)\t0.3298135460236378\n",
            "  (298, 275)\t0.3298135460236378\n",
            "  (298, 82)\t0.3298135460236378\n",
            "  (298, 47)\t0.3298135460236378\n",
            "  (299, 1134)\t0.1707680070297463\n",
            "  (299, 1011)\t0.5105046878796011\n",
            "  (299, 814)\t0.37168031636409965\n",
            "  (299, 613)\t0.15538396142226923\n",
            "  (299, 265)\t0.16340974785534534\n",
            "  (299, 148)\t0.5105046878796011\n",
            "  (299, 26)\t0.5105046878796011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nrGKLhKJJBKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train ML\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_TF, df['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2H7xM7bJUiB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "#docs_new = ['o lula deve ficar livre', 'politicos são corruptos', 'Marina ladrão', 'bom noite']\n",
        "#X_new_counts = count_vect.transform(docs_new)\n",
        "#X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "#predicted = clf.predict(X_new_tfidf)\n",
        "#print(predicted)\n",
        "\n",
        "#for doc, category in zip(docs_new, predicted):\n",
        "#  if category == 0:\n",
        "#    print('%r => %s' % (doc, \"direita\"))\n",
        "#  elif category == 1:\n",
        "#    print('%r => %s' % (doc, \"esquerda\"))\n",
        "#  else:\n",
        "#    print('%r => %s' % (doc, \"neutro\"))\n",
        "      \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JJpnKGa0FFaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from tweepy import OAuthHandler\n",
        "#from tweepy import API\n",
        "#from tweepy import Cursor\n",
        "#from datetime import datetime, date, time, timedelta\n",
        "#from collections import Counter\n",
        "#import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aS5TQIqUFl_8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Auth GDrive\n",
        "#from google.colab import auth\n",
        "#auth.authenticate_user()\n",
        "\n",
        "#import gspread\n",
        "#from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKhi1cUWGFZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Credentials\n",
        "#APP_KEY = 'B6cZTTHoeMr96AFfOsbVM2lGG'\n",
        "#APP_SECRET = 'QhGt5p4TsGVK8tOds1fWc7hEDIFfrgnTW94fenpl1WneWLWqfz'\n",
        "#OAUTH_TOKEN = '167813147-tP4vOpAZFlcfRLlqXWMfRqcBW3yvjNpzRAborOUu'\n",
        "#OAUTH_TOKEN_SECRET = '8UshaZNMspgdN2kRuSlkPbBJfYdu3UDzOzZt0R1F8JoU7'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8fzUL3oOuCw",
        "colab_type": "code",
        "outputId": "59dcf8fd-f7e2-4ce8-d71c-8eafe21ff9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import API\n",
        "\n",
        "\n",
        "#consumer_key='B6cZTTHoeMr96AFfOsbVM2lGG'\n",
        "#consumer_secret='QhGt5p4TsGVK8tOds1fWc7hEDIFfrgnTW94fenpl1WneWLWqfz'\n",
        "#access_token='167813147-tP4vOpAZFlcfRLlqXWMfRqcBW3yvjNpzRAborOUu'\n",
        "#access_token_secret='8UshaZNMspgdN2kRuSlkPbBJfYdu3UDzOzZt0R1F8JoU7'\n",
        "\n",
        "auth = tweepy.OAuthHandler(APP_KEY, APP_SECRET)\n",
        "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "\n",
        "number_of_tweets =10\n",
        "tweets = api.user_timeline(screen_name = '@alanprando', count=10)\n",
        "\n",
        "tmp = []\n",
        "\n",
        "tweets_for_csv = [tweet.text for tweet in tweets]\n",
        "for j in tweets_for_csv:\n",
        "  tmp.append(j)\n",
        "\n",
        "print(tmp)  \n",
        "\n",
        "#for status in tweepy.Cursor(api.user_timeline, screen_name='@alanprando', tweet_mode='extended').items(10):\n",
        "#  print(status.full_text)\n",
        "\n",
        "  \n",
        "#print(tmp.shape)\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['RT @TheNoiteVideos: Acelera São Paulo https://t.co/z3waJJIIqA', 'RT @OGloboPolitica: Ex-assessor de @FlavioBolsonaro fez saques em 14 bairros, aponta relatório do Coaf https://t.co/R8UD8RIlyn https://t.co…', 'RT @joaoamoedonovo: Concordo com a avaliação de Paulo Guedes. O Sistema S deve ser revisto e suas contribuições, que atualmente são obrigat…', 'RT @joaoamoedonovo: Isso é NOVO.\\n\\n✅Redução de 21 para 11 secretarias\\n✅Não morar em palácio\\n✅Dispensar a frotas de de helicópteros e aviões…', 'RT @da_cia: Luciano Huck, meu, puta cara antenado com a Educação, bicho. Precisamos dessa galera https://t.co/twrT7bfKLJ', 'RT @gabrielazevedo: Uma informação básica: é possível se opor ao PT e ao PSL ao mesmo tempo? É possível. No Brasil, uma pessoa pode não gos…', 'RT @JovemPanNews: \"Você quer ser preso?\", diz Lewandowski a passageiro de avião em vídeo que circula nas redes sociais. https://t.co/teuzlb…', 'RT @janainalimasp: O NOVO assumiu o compromisso de acabar com os privilégios na política brasileira. Como vereadora, honro essa responsabil…', 'RT @oiluiz: 1. Políticos enrolados na Lava Jato votam pelo aumento do salário do STF \\n\\n2. Temer aprova o aumento \\n\\n3. STF agora vota o indu…', 'RT @foIha_sp: @folha A concorrência tá forte hein!!!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2F2-etWY9SRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c01e29f2-986d-4dc0-b30a-5245a940c17c"
      },
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "docs_new_N= tmp\n",
        "X_new_counts_N = count_vect.transform(docs_new_N)\n",
        "X_new_tfidf_N = tfidf_transformer.transform(X_new_counts_N)\n",
        "\n",
        "predicted_N = clf.predict(X_new_tfidf_N)\n",
        "print(predicted_N)\n",
        "\n",
        "for doc, category in zip(docs_new_N, predicted_N):\n",
        "  if category == 0:\n",
        "    print('%r => %s' % (doc, \"direita\"))\n",
        "  elif category == 1:\n",
        "    print('%r => %s' % (doc, \"esquerda\"))\n",
        "  else:\n",
        "    print('%r => %s' % (doc, \"neutro\"))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 1 0 1 1 1 1 1]\n",
            "'RT @TheNoiteVideos: Acelera São Paulo https://t.co/z3waJJIIqA' => direita\n",
            "'RT @OGloboPolitica: Ex-assessor de @FlavioBolsonaro fez saques em 14 bairros, aponta relatório do Coaf https://t.co/R8UD8RIlyn https://t.co…' => esquerda\n",
            "'RT @joaoamoedonovo: Concordo com a avaliação de Paulo Guedes. O Sistema S deve ser revisto e suas contribuições, que atualmente são obrigat…' => direita\n",
            "'RT @joaoamoedonovo: Isso é NOVO.\\n\\n✅Redução de 21 para 11 secretarias\\n✅Não morar em palácio\\n✅Dispensar a frotas de de helicópteros e aviões…' => esquerda\n",
            "'RT @da_cia: Luciano Huck, meu, puta cara antenado com a Educação, bicho. Precisamos dessa galera https://t.co/twrT7bfKLJ' => direita\n",
            "'RT @gabrielazevedo: Uma informação básica: é possível se opor ao PT e ao PSL ao mesmo tempo? É possível. No Brasil, uma pessoa pode não gos…' => esquerda\n",
            "'RT @JovemPanNews: \"Você quer ser preso?\", diz Lewandowski a passageiro de avião em vídeo que circula nas redes sociais. https://t.co/teuzlb…' => esquerda\n",
            "'RT @janainalimasp: O NOVO assumiu o compromisso de acabar com os privilégios na política brasileira. Como vereadora, honro essa responsabil…' => esquerda\n",
            "'RT @oiluiz: 1. Políticos enrolados na Lava Jato votam pelo aumento do salário do STF \\n\\n2. Temer aprova o aumento \\n\\n3. STF agora vota o indu…' => esquerda\n",
            "'RT @foIha_sp: @folha A concorrência tá forte hein!!!' => esquerda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nSPHFBgU-4rT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4bf3d21a-f113-4a52-a5bc-6291ec78fc69"
      },
      "cell_type": "code",
      "source": [
        "#import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "\n",
        "def descriptive_stats(distribuition):\n",
        "\n",
        "  dist = np.array(distribuition)\n",
        "  \n",
        "  print 'scores', len(dist)\n",
        "\n",
        "#d = {'name':pd.Series(['1','2','3','4','5','6','7','8','9','10']), 'Categoria':pd.Series(predicted_N.T)}\n",
        "#d = {'Categoria':pd.Series(predicted_N.T)}\n",
        "\n",
        "#df = pd.DataFrame(d)\n",
        "#print(df.shape)\n",
        "#print df. describe(include=['all'])\n",
        "\n",
        "\n",
        "#results = predicted_N.count()\n",
        "#print(results)\n",
        "\n",
        "#from scipy import stats\n",
        "#for arr in predicted_N.T:\n",
        "#  print(stats.describe(arr))\n",
        "  \n",
        "#print(\"valor medio\", predicted_N.mean()) \n",
        "#print(\"valor maximo\", predicted_N.max()) \n",
        "#print(\"valor minimo\", predicted_N.min()) \n",
        "#print(\"valor minimo\", predicted_N.shape()) \n",
        "descriptive_stats(predicted_N)\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-5764ae0bb87a>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    print 'scores', len(dist)\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}